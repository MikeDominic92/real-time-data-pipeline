# Deployment Configuration

# Environment-specific settings
environments:
  development:
    project_id: "video-deal-analyzer-449617"
    region: "us-central1"
    machine_type: "n1-standard-2"
    num_workers: 2
    max_batch_size: 100
    monitoring:
      stackdriver_logging: true
      error_reporting: true
      profiling: false

  staging:
    project_id: "video-deal-analyzer-449617"
    region: "us-central1"
    machine_type: "n1-standard-4"
    num_workers: 4
    max_batch_size: 500
    monitoring:
      stackdriver_logging: true
      error_reporting: true
      profiling: true

  production:
    project_id: "video-deal-analyzer-449617"
    region: "us-central1"
    machine_type: "n1-standard-8"
    num_workers: 8
    max_batch_size: 1000
    monitoring:
      stackdriver_logging: true
      error_reporting: true
      profiling: true

# Dataflow job settings
dataflow:
  temp_location: "gs://video-deal-analyzer-449617-dataflow-temp"
  staging_location: "gs://video-deal-analyzer-449617-dataflow-staging"
  zone: "us-central1-a"
  network: "default"
  subnetwork: "regions/us-central1/subnetworks/default"
  service_account_email: "github-actions-sa@video-deal-analyzer-449617.iam.gserviceaccount.com"
  max_workers: 10
  autoscaling_algorithm: "THROUGHPUT_BASED"

# Resource requirements
resources:
  min_cpu_platform: "Intel Skylake"
  disk_size_gb: 100
  disk_type: "pd-standard"
  worker_disk_type: "pd-ssd"

# Pipeline settings
pipeline:
  batch_size: 1000
  window_size: 60  # seconds
  allowed_lateness: 300  # seconds

# Security settings
security:
  kms_key_name: "projects/video-deal-analyzer-449617/locations/us-central1/keyRings/dataflow-kr/cryptoKeys/dataflow-key"
  use_public_ips: false
  enable_streaming_engine: true

# Monitoring and logging
monitoring:
  job_name_prefix: "rtdp"
  update_interval_seconds: 10
  dataflow_service_options:
    - "enable_prime"
    - "enable_streaming_engine"
  experiments:
    - "use_runner_v2"
    - "use_unified_worker"
    - "use_sdk_worker"
