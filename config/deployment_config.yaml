# Deployment Configuration

# Environment-specific settings
environments:
  development:
    project_id: "your-dev-project-id"
    region: "us-central1"
    machine_type: "n1-standard-2"
    num_workers: 2
    max_batch_size: 100
    monitoring:
      stackdriver_logging: true
      error_reporting: true
      profiling: false

  staging:
    project_id: "your-staging-project-id"
    region: "us-central1"
    machine_type: "n1-standard-4"
    num_workers: 4
    max_batch_size: 500
    monitoring:
      stackdriver_logging: true
      error_reporting: true
      profiling: true

  production:
    project_id: "your-prod-project-id"
    region: "us-central1"
    machine_type: "n1-standard-8"
    num_workers: 8
    max_batch_size: 1000
    monitoring:
      stackdriver_logging: true
      error_reporting: true
      profiling: true

# Dataflow job settings
dataflow:
  temp_location: "gs://{project_id}-dataflow-temp"
  staging_location: "gs://{project_id}-dataflow-staging"
  zone: "us-central1-a"
  network: "default"
  subnetwork: "regions/{region}/subnetworks/default"
  service_account_email: "dataflow-sa@{project_id}.iam.gserviceaccount.com"
  max_workers: 10
  autoscaling_algorithm: "THROUGHPUT_BASED"

# Resource requirements
resources:
  min_cpu_platform: "Intel Skylake"
  worker_disk_type: "pd-ssd"
  worker_disk_size_gb: 50
  shuffle_mode: "service"

# Security settings
security:
  kms_key_name: "projects/{project_id}/locations/{region}/keyRings/dataflow-kr/cryptoKeys/dataflow-key"
  use_public_ips: false
  enable_streaming_engine: true

# Monitoring and logging
monitoring:
  job_name_prefix: "rtdp"
  update_interval_seconds: 10
  dataflow_service_options:
    - "enable_prime"
    - "enable_streaming_engine"
  experiments:
    - "use_runner_v2"
    - "use_unified_worker"
    - "use_sdk_worker"
